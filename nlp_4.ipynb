{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMgxWJDTyyVu",
        "outputId": "f36a9ff5-cb99-44b8-831b-11427e172446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized word: meet\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word = \"meeting\"\n",
        "\n",
        "lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "\n",
        "print(\"Lemmatized word:\", lemma)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"The dogs are running\"\n",
        "\n",
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "\n",
        "tagged = pos_tag(tokens)\n",
        "\n",
        "lemmatized_words = [\n",
        "    lemmatizer.lemmatize(word, pos='v' if tag.startswith('V') else 'n')\n",
        "    for word, tag in tagged\n",
        "]\n",
        "\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3RWKK4V03J9",
        "outputId": "d6e7342f-0a97-4c49-d66d-93083fb75d22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'dog', 'be', 'run']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_percetron_tagger_eng')\n",
        "\n",
        "text = \"nltk is a powerful library for natural language processing\"\n",
        "words = word_tokenize(text)\n",
        "\n",
        "pos_tags = pos_tag(words)\n",
        "\n",
        "\n",
        "print(\"original taxt:\")\n",
        "print(text)\n",
        "\n",
        "\n",
        "print(\"\\npos tags:\")\n",
        "for word,pos_tag in pos_tags:\n",
        "  print(f\"{word}: {pos_tag}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EaBKvod5ZCo",
        "outputId": "12cc9708-5d78-4db9-ec84-56d7b1fcb427"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original taxt:\n",
            "nltk is a powerful library for natural language processing\n",
            "\n",
            "pos tags:\n",
            "nltk: NN\n",
            "is: VBZ\n",
            "a: DT\n",
            "powerful: JJ\n",
            "library: NN\n",
            "for: IN\n",
            "natural: JJ\n",
            "language: NN\n",
            "processing: NN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Error loading averaged_percetron_tagger_eng: Package\n",
            "[nltk_data]     'averaged_percetron_tagger_eng' not found in index\n"
          ]
        }
      ]
    }
  ]
}